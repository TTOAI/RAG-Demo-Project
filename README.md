# foss-2025-2-final

## 이름
이주영

## 학번 
20216818

## 동기
<p>
LLM의 기술적 발전은 많은 곳에서 도움이 되고 있다.
하지만 LLM은 아직 학습하지 못한 최신 정보, 특정 분야, 조직 내부 데이터 등에 대해서는 정확한 답변을 주지 못한다.
또한 이것은 할루시네이션 문제 혹은 신뢰도가 낮고 설명력이 부족한 정보의 생성으로 이어진다.
<br>
이와 관련하여 본 프로젝트에서는 RAG 구조를 활용하여 무료 오픈소스 도구만으로 문서 기반 질의응답 시스템을 구현하여 사용자의 관심 분야에 대한 정확도 높은 답변을 제공하는 것을 목표로 본 주제를 선정하였다.
</p>
<p>
검색 증강 생성(Retrieval-augmented generation, RAG)은 대형 언어 모델 (LLM)이 새로운 정보를 검색하고 통합할 수 있도록 하는 기술이다.
RAG를 사용하면 LLM은 지정된 문서 집합을 참조할 때까지 사용자 쿼리에 응답하지 않는다. 
이 문서들은 LLM의 기존 훈련 데이터의 정보를 보완한다.
이를 통해 LLM은 훈련 데이터에서 사용할 수 없는 도메인 특정 및 업데이트된 정보를 사용할 수 있다.
예를 들어, 이는 LLM 기반 챗봇이 내부 회사 데이터에 접근하거나 권위 있는 출처를 기반으로 응답을 생성하는 데 도움이 된다. 
(출처: [위키백과 - 검색증강생성성](https://ko.wikipedia.org/wiki/%EA%B2%80%EC%83%89%EC%A6%9D%EA%B0%95%EC%83%9D%EC%84%B1))
</p>

## 수행 내용
### 1. 실행환경 세팅
- Docker Compose 기반 FastAPI + Qdrant 환경 구성
- 서버 및 Swagger 정상 동작 확인

### 2. 문서 Ingestion & Chunking
- 문서 정제 기능 구현
- 문서를 일정 길이의 chunk로 분할
- `/ingest` API를 통해 chunk 결과 반환

### 3. Embedding
- Sentence-Transformers(all-MiniLM-L6-v2) 기반 embedding 적용
- `/test-embed` API로 embedding 벡터 테스트

## 토의
